<!DOCTYPE html>
<html lang="en">
  <head>
  <!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-106549244-1"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-106549244-1', 'auto');
  ga('send', 'pageview');

</script>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="wistrongh=device-wistrongh, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <!--<link rel="icon" href="../../favicon.ico"> -->

    <title>NeurIPS 2018 Workshop: Critiquing and Correcting Trends in Machine Learning</title>

    <!-- Bootstrap core CSS -->
    <link href="dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="assets/css/grid.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <script src="assets/js/ie-emulation-modes-warning.js"></script>
    
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="dist/js/bootstrap.min.js"></script>

<script>
$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip(); 
});
</script>

  </head>

  <body>
    <div class="container">

      <div class="page-header">
        <h1>Critiquing and Correcting Trends in Machine Learning <small>NeurIPS 2018 Workshop</small></h1>
        <p class="lead"><em>Organizers:</em> <span data-toggle="tooltip" title="University of Oxford">Benjamin&nbsp;Bloem-Reddy</span> , <span data-toggle="tooltip" title="Alan Turing Institute">Brooks&nbsp;Paige</span> , <span data-toggle="tooltip" title="University of Oxford">Matt&nbsp;J.&nbsp;Kusner</span> , <span data-toggle="tooltip" title="Microsoft Research">Rich&nbsp;Caruana</span> , <span data-toggle="tooltip" title="University of Oxford">Tom&nbsp;Rainforth</span> , <span data-toggle="tooltip" title="University of Oxford">Yee&nbsp;Whye&nbsp;Teh</span>   </p>
        <h4>Rooms 511 ABDE<br /><br />December 7, 2018 - Palais des Congrès de Montréal, Montréal, CANADA</h4>
      </div>
	 
  <div class="jumbotron jumbotron-fluid">
  		<div class="container">
    	<h2>Call for Papers</h2>
    	<p class="lead"><small><mark><u>Deadline</u>: October 30, 2018, 11:59 PM UTC</mark></small></p>
    	<p class="lead">
    	<!--We call for papers that critically examine current common practices and/or trends in methodology, datasets, empirical standards, publication models, or any other aspect of machine learning research. -->
      <p>The one day NeurIPS 2018 Workshop: Critiquing and Correcting Trends in Machine Learning calls for papers that critically examine current common practices and/or trends in methodology, datasets, empirical standards, publication models, or any other aspect of machine learning research. Though we are happy to receive papers that bring attention to problems for which there is no clear immediate remedy, we particularly encourage papers which propose a solution or indicate a way forward. Papers should motivate their arguments by describing gaps in the field. Crucially, this is not a venue for settling scores or character attacks, but for moving machine learning forward as a scientific discipline.</p>

        <p>To help guide submissions, we have split up the call for papers into the follows tracks. Please indicate the intended track when making your submission. Papers are welcome from all subfields of machine learning. If you have a paper which you feel falls within the remit of the workshop but does not clearly fit one of these tracks, please contact the organizers at: ml.critique.correct@gmail.com.</p>

        <p><b>Bad Practices</b> (1-4 pages)<br />
        Papers that highlight common bad practices or unjustified assumptions at any stage of the research process. These can either be technical shortfalls in a particular machine learning subfield, or more procedural bad practices of the ilk of those discussed in [17]. When possible, papers should also try to highlight work which does not fall foul of these bad practices, as examples of how they can be avoided.</p>

        <p><b>Flawed Intuitions or Unjustified Assumptions</b> (3-4 pages)<br/>
        Papers that call into question commonly held intuitions or provide clear evidence either for or against assumptions that are regularly taken for granted without proper justification. For example, we would like to see papers which provide empirical assessments to test out metrics, verify intuitions, or compare popular current approaches with historic baselines that may have unfairly fallen out of favour (see e.g. [2]). Such submissions are encouraged regardless of whether these assessments ultimately result in positive or negative results. We would also like to see work which provides results which makes us rethink our intuitions or the assumptions we typically make.</p>

<p><b>Negative Results</b> (3-4 pages)<br />
Papers which show failure modes of existing algorithms or suggest new approaches which one might expect to perform well but which do not. The aim of the latter of these is to provide a venue for work which might otherwise go unpublished but which is still of interest to the community, for example by dissuading other researchers from similar ultimately unsuccessful approaches. Though it is inevitably preferable that papers are able to explain why the approach performs poorly, this is not essential if the paper is able to demonstrate why the negative result is of interest to the community in its own right.</p>

<p><b>Research Process</b> (1-4 pages)<br />
Papers which provide carefully thought through critiques, provide discussion on, or suggest new approaches to areas such as the conference model, the reviewing process, the role of industry in research, open sourcing of code and data, institutional biases and discrimination in the field, research ethics, reproducibility standards, and allocation of conference tickets.</p>  

<p><b>Debates</b> (1-2 pages)<br />
Short proposition papers which discuss issues either affecting all of machine learning or significantly sized subfields (e.g. reinforcement learning, Bayesian methods, etc). Selected papers will be used as the basis for instigating online forum debates before the workshop, leading up to live discussions on the day itself.</p>

<p><b>Open Problems</b> (1-4 pages/short talks)<br />
Papers that describe either (a) unresolved questions in existing fields that need to be addressed, (b) desirable operating characteristics for ML in particular application areas that have yet to be achieved, or (c) new frontiers of machine learning research that require rethinking current practices (e.g., error diagnosis for when many ML components are interoperating within a system, automating dataset collection/creation).</p>

      
        <p><b>Submission Instructions</b><br />
        Papers should be submitted as pdfs using the <a href="https://neurips.cc/Conferences/2018/PaperInformation/StyleFiles" role="button">NeurIPS LaTeX style file</a>.  <b>Author names should be anonymized.</b></p>

        <p><b>Acceptance and Registrations</b><br />
        All accepted papers will be made available through the workshop website and presented as a poster. Selected papers will also be given contributed talks. We are able to add a moderate number of accepted paper authors to the pool of reserved tickets. In the event that the number of accepted papers exceeds our reserved ticket allocation, assignments to the reserved ticket pool will be allocated based on review scores. We further have a small number of complimentary workshop registrations that will be handed out to selected papers. If any authors are unable to attend the workshop due visa, ticketing, or funding issues, they will be allowed to provide a video presentation for their work that will be made available through the workshop website in lieu of a poster presentation.</p>

        <p>Please submit papers here: <a href="https://easychair.org/conferences/?conf=cract2018" class="btn btn-default btn-xs" role="button">https://easychair.org/conferences/?conf=cract2018</a></p>
    	</p>



    	<!--<p class="lead"><strong></strong></p>
    	<p class="lead">
  			<button type="button" class="btn btn-primary btn-lg" data-toggle="modal" data-target="#myModal">Learn more</button>
  		</p>-->
    	</div>
	 </div>

<!-- Modal -->
<div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span> </button>
        <h4 class="modal-title" id="myModalLabel">Call for Papers</h4>
      </div>
      <div class="modal-body">
      	
<!--      	<p>The one day NIPS 2018 Workshop on Critiquing and Correcting Trends in Machine Learning calls for papers that critically examine current common practices and/or trends in methodology, datasets, empirical standards, publication models, or any other aspect of machine learning research. Though we are happy to receive papers that bring attention to problems for which there is no clear immediate remedy, we particularly encourage papers which propose a solution or indicate a way forward.  Papers should motivate their arguments by describing gaps in the field. Crucially, this is not a venue for settling scores or character attacks, but for moving machine learning forward as a scientific discipline.</p>

        <p>To help guide submissions, we have split up the call for papers into the follows tracks.  Please indicate the intended track when making your submission.  Papers are welcome from all subfields of machine learning.  If you have a paper which you feel falls within the remit of the workshop but does not clearly fit one of these tracks, please contact the organizers at: ml.critique.correct@gmail.com.</p>

        <p><b>Bad Practices</b> (1-4 pages)<br />
        Papers that highlight common bad practices or unjustified assumptions at any stage of the research process.  These can either be technical shortfalls in a particular machine learning subfield, or more procedural bad practices of the ilk of those discussed in [17].</p>

        <p><b>Common Misconceptions</b> (3-4 pages)<br/>
        Papers that call into question commonly held intuitions or provide clear evidence either for or against assumptions that are regularly taken for granted without proper justification. For example, we would like to see papers which provide empirical assessments to test out metrics, verify intuitions, or compare popular current approaches with historic baselines that may have unfairly fallen out of favour (see e.g. [2]).  We would also like to see work which provides results which makes us rethink our intuitions or the assumptions we typically make.</p>

<p><b>Negative Results</b> (3-4 pages)<br />
Papers which show failure modes of existing algorithms or suggest new approaches which one might expect to perform well but which do not.  The aim of the latter of these is to provide a venue for work which might otherwise go unpublished but which is still of interest to the community, for example by dissuading other researchers from similar ultimately unsuccessful approaches.  Though it is inevitably preferable that papers are able to explain why the approach performs poorly, this is not essential if the paper is able to demonstrate why the negative result is of interest to the community in its own right.</p>

<p><b>Research Process</b> (2-4 pages)<br />
Papers which provide carefully thought through critiques, provide discussion on or suggest new approaches to areas such as the conference model, the reviewing process, the role of industry in research, open sourcing of code and data, institutional biases and discrimination in the field, research ethics, reproducibility standards, and allocation of conference tickets.  

<p><b>Debates</b> (1-2 pages)
Short proposition papers which discuss issues either affecting all of machine learning or significantly sized subfields (e.g. reinforcement learning, Bayesian methods, etc).  Selected papers will be used as the basis for instigating online forum debates before the workshop, leading up to live discussions on the day itself.</p>

<p><b>Open Problems</b> (1-2 papers/short talks)<br />
Papers that describe either (a) unresolved questions in existing fields that need to be addressed (b) desirable operating characteristics for ML in particular application areas that have yet to be achieved or (c) new frontiers of machine learning research that require rethinking current practices (e.g., error diagnosis for when many ML components are inter-operating within a system, automating dataset collection/creation).</p>

      
      	<h5>Submission Instructions</h5>
      	<p>Papers should be submitted as pdfs using the <a href="https://nips.cc/Conferences/2018/PaperInformation/StyleFiles" role="button">NIPS LaTeX style file</a>.  Author names do not need to be anonymized and page limits do not include references.  Appendices are allowed after the references but reviewers will not be obliged to read them.</p>      	
      	<p>Please email all submissions to: <a href="mailto:ml.critique.correct@gmail.com" class="btn btn-default btn-xs" role="button">ml.critique.correct@gmail.com</a></p>
-->
      	<br>
      	<div class="alert alert-warning" role="alert"><div class="glyphicon glyphicon-exclamation-sign"></div> <u>Deadline</u>: October 23, 2018</div>
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
      </div>
    </div>
  </div>
</div>
      
      	<h2>Abstract</h2>
      	
      	<p>Recently there have been calls to make machine learning more reproducible, less hand-tailored, fair, and generally more thoughtful about how research is conducted and put into practice. These are hallmarks of a mature scientific field and will be crucial for machine learning to have the wide-ranging, positive impact it is expected to have. Without careful consideration, we as a field risk inflating expectations beyond what is possible. To address this, this workshop aims to better understand and to improve all stages of the research process in machine learning.</p>
<p>A number of recent papers have carefully considered trends in machine learning as well as the needs of the field when used in real-world scenarios [1-18]. Each of these works introspectively analyzes what we often take for granted as a field. Further, many propose solutions for moving forward. The goal of this workshop is to bring together researchers from all subfields of machine learning to highlight open problems and widespread dubious practices in the field, and crucially, to propose solutions. We hope to highlight issues and propose solutions in areas such as: <br />
- Common practices [1, 8]<br />
- Implicit technical and empirical assumptions that go unquestioned [2, 3, 5, 7, 11, 12, 13, 17, 18]<br />
- Shortfalls in publication and reviewing setups [15, 16]<br />
- Disconnects between research focus and application requirements [9, 10, 14]<br />
- Surprising observations that make us rethink our research priorities [4, 6]
</p>



<p>The workshop program is a collection of invited talks, alongside contributed posters and talks. For some of these talks, we plan a unique open format of 10 minutes of talk + 10 minutes of follow up discussion. Additionally, a separate panel discussion will collect researchers with a diverse set of viewpoints on the current challenges and potential solutions. During the panel, we will also open the conversation to the audience. The discussion will further be open to an online Q&A which will be solicited prior to the workshop. </p>
<p>A key expected outcome of the workshop is a collection of important open problems at all levels of machine learning research, along with a record of various bad practices that we should no longer consider to be acceptable. Further, we hope that the workshop will make inroads in how to address these problems, highlighting promising new frontiers for making machine learning practical, robust, reproducible, and fair when applied to real-world problems. </p>
     

<!--08:00 - 08:15   Opening Remarks
08:15 - 09:30   Invited Talks
09:30 - 11:10   Contributed Talks and Following Discussions
11:10 - 12:15   Poster Session
12:15 - 13:30   Lunch
13:30 - 14:30   Invited Talks
14:30 - 15:30   Panel Discussion
15:30 - 16:00   Coffee Break
16:00 - 17:15   Invited Talks
17:15 -     Poster Session 	-->		

<div class="row">
  <div class="col-md-12">
    <h3>We are soliciting questions for the Panel Discussion here!: <a href="https://bit.ly/2UdjMJP">https://bit.ly/2UdjMJP</a></h3>
    <h3>Schedule (Rooms 511 ABDE)</h3>

      <table class="table">
      <tbody>
        <tr>
          <td>08:30</td>
          <td><strong>Opening remarks</strong></td>
          <td></td>
          <td></td>
        </tr>
        <!--<tr>
          <td colspan="3"><div class="text-center"><small><strong>On Trends in Machine Learning</strong></small></div></td>
        </tr>-->
         <tr class="active">
          <td>08:40</td>
          <td>Invited talk</td>
          <td>But it’s hard! <button style="outline: 0; border: 0;" type="button" class="label label-default" data-toggle="modal" data-target="#zachModal">Abstract</button></td>
          <td>Zachary Lipton</td>
         </tr>
        <tr class="active">
          <td>09:05</td>
          <td>Invited talk</td>
          <td>Applied Machine Learning at Facebook Scale: Separating Opportunity from Hype <button style="outline: 0; border: 0;" type="button" class="label label-default" data-toggle="modal" data-target="#kimModal">Abstract</button></td>
          <td>Kim Hazelwood</td>
         </tr>
        <tr style="background: repeating-linear-gradient(45deg, #f5f5f5, #f5f5f5 4px, white 4px, white 10px);">
          <td>09:30</td>
          <td>Contributed talk</td>
          <td>Expanding search in the space of empirical ML</td>
          <td>Bronwyn Woods</td>
        </tr>
        <tr style="background: repeating-linear-gradient(45deg, #f5f5f5, #f5f5f5 4px, white 4px, white 10px);">
          <td>09:40</td>
          <td>Contributed talk</td>
          <td>Opportunities for machine learning research to support fairness in industry practice</td>
          <td>Kenneth Holstein</td>
        </tr>
        <tr style="background: repeating-linear-gradient(45deg, #F9E59D, #F9E59D 4px, white 4px, white 10px);">
          <td>09:50</td>
          <td>Spotlights</td>
          <td>Surprising Negative Results for Generative Adversarial Tree Search<br />
              Let's Play Again: Variability of Deep Reinforcement Learning Agents in Atari Environments<br />
              Please Stop Explaining Black Box Models for High Stakes Decisions<br />
              Theoretical guarantees and empirical evaluation: how large is the gap?<br />
              Can VAEs Generate Novel Examples?<br />
              Language GANs Falling Short</td>
              <!--Papers 2, 23, 24, 36, 40, 44-->
          <td></td>
        </tr>
        <tr>
          <td>10:20</td>
          <td colspan="3"><span class="label label-warning">Poster Session 1 & Coffee break</span> </td>
        </tr>
         <tr class="active">
          <td>11:10</td>
          <td>Invited talk</td>
          <td>Correcting and Critiquing Trends in Interpretable ML <button style="outline: 0; border: 0;" type="button" class="label label-default" data-toggle="modal" data-target="#finaleModal">Abstract</button></td>
          <td>Finale Doshi-Velez</td>
         </tr>
        <tr class="active">
          <td>11:35</td>
          <td>Invited talk</td>
          <td><span style="color: #dddddd">TBA</span></td>
          <td>Suchi Saria</td>
         </tr>
       <tr class="warning">
          <td>12:00</td>
          <td colspan="3"><strong>Lunch</strong></td>
        </tr>   
         <tr class="active">
          <td>13:30</td>
          <td>Invited talk</td>
          <td>Are we making progress? <button style="outline: 0; border: 0;" type="button" class="label label-default" data-toggle="modal" data-target="#sebastianModal">Abstract</button></td>
          <td>Sebastian Nowozin</td>
        </tr>
        <tr style="background: repeating-linear-gradient(45deg, #f5f5f5, #f5f5f5 4px, white 4px, white 10px);">
          <td>13:55</td>
          <td>Contributed talk</td>
          <td>Using Cumulative Distribution Based Performance Analysis to Benchmark Models</td>
          <td>Scott Jordan</td>
        </tr>
        <tr class="active">
          <td>14:05</td>
          <td>Invited talk</td>
          <td>Reviewing models, prepublication models, and other things that tend to make people upset <button style="outline: 0; border: 0;" type="button" class="label label-default" data-toggle="modal" data-target="#charlesModal">Abstract</button></td>
          <td>Charles Sutton</td>
        </tr>
        <tr style="background: repeating-linear-gradient(45deg, #f5f5f5, #f5f5f5 4px, white 4px, white 10px);">
          <td>14:30</td>
          <td>Contributed talk</td>
          <td>On Avoiding Tragedy of the Commons in the Peer Review Process</td>
          <td>D. Sculley</td>
        </tr>
      <tr style="background: repeating-linear-gradient(45deg, #F9E59D, #F9E59D 4px, white 4px, white 10px);">
          <td>14:40</td>
          <td>Spotlights</td>
          <td>Conference ticket allocation via non-uniform random selection to address systemic biases<br />
              Distilling Information from a Flood: A Possibility for the Use of Meta-Analysis and Systematic Review in Machine Learning Research<br />
              What's in a name? It's time to nip NIPS<br />
              Code as Scholarship: Extensible Software Experiments
              <!--Papers 10, 20, 35, 42--></td>
          <td></td>
        </tr>
      <tr>
          <td>15:00</td>
          <td colspan="3"><span class="label label-warning">Poster Session 2 & Coffee break</span> </td>
        </tr>
      <tr class="info">
          <td>15:30</td>
          <td><strong>Panel on Research Process</strong></td>
          <td>Suchi Saria, Charles Sutton, Finale Doshi-Velez, Hanna Wallach, Rich Caruana, Zachary Lipton<br />
              <strong>Feel free to add questions for the panel discussion:</strong> <a href="https://bit.ly/2UdjMJP">https://bit.ly/2UdjMJP</a></td>
          <td></td>
        </tr> 
      <tr>
          <td>16:30</td>
          <td colspan="3"><span class="label label-warning">Poster Session 3</span> </td>
        </tr>
      </tbody>
    </table>
    
</div>
  <!--<div class="col-md-6">
	
	<h3>List of Speakers</h3>
      <table class="table table-striped">
      <thead>
        <tr>
          <th>Name</th>
          <th>Affiliation</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Suchi Saria</td>
          <td>Johns Hopkins University</td>
        </tr>
         <tr>
          <td>Charles Sutton</td>
          <td>University of Edinburgh</td>
        </tr>
        <tr>
          <td>Kim Hazelwood</td>
          <td>Facebook</td>
        </tr>
        <tr>
          <td>Zach Lipton</td>
          <td>Carnegie Mellon University</td>
        </tr>
        <tr>
          <td>Finale Doshi-Velez</td>
          <td>Harvard University</td>
        </tr>        
        <tr>
          <td>Sebastian Nowozin</td>
          <td>Microsoft</td>
        </tr>
        <tr>
      </tbody>
    </table>
	
  </div>-->
</div>





<div class="modal fade" id="zachModal" tabindex="-1" role="dialog" aria-hidden="true">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
        <h4 class="modal-title">But it’s hard!</h4>
      </div>
      <div class="modal-body">
      <p>The machine learning community is struggling to deal with several well-documented crises in scholarship: (i) a blurring of fact and fancy (ii) experiments divorced from falsifiability (iii) math that cannot, should not, and isn’t even meant to be followed, and (iv) exposition that sows confusion and distorts the public discourse. However, in other ways, the field is healthier than ever: (a) vibrant economy supports careers in machine learning, (b) mature tooling makes algorithms easier to run and experiments easier to reproduce, and (c) the field is far more welcoming and accessible to new talent. While it’s easy to gather a few scholars and form a consensus about what researchers should/should not do, how to effect change at a community level is less clear. What levers are available to influence behavior? Who should pull them? And which interventions will curb flawed scholarship without undermining the community’s strengths? This talk will aim to present a balanced picture, both of the status quo, the ecosystem that supports it, and the difficulty of improving upon it.</p>
     </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
      </div>
    </div>
  </div>
</div>

<div class="modal fade" id="finaleModal" tabindex="-1" role="dialog" aria-hidden="true">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
        <h4 class="modal-title">Correcting and Critiquing Trends in Interpretable ML</h4>
      </div>
      <div class="modal-body">
      <p>Interpretable ML has become a subfield of ML in its own right: not only are the numbers of papers in interpretable ML increasing, but interpretable ML is now a keyword for submissions and interpretable ML workshops are common at major ML conferences.  Given the importance of interpretability in many real world contexts, this trend is great!  However, as a relatively young subfield -- and one that goes beyond traditional ML boundaries -- norms around definitions and evaluation metrics are still in formation.  In this talk, I will discuss some of our work on creating validated metrics, as well as provide my perspectives on what those norms should be.</p>
     </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
      </div>
    </div>
  </div>
</div>

<div class="modal fade" id="kimModal" tabindex="-1" role="dialog" aria-hidden="true">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
        <h4 class="modal-title">Applied Machine Learning at Facebook Scale: Separating Opportunity from Hype</h4>
      </div>
      <div class="modal-body">
      <p>At Facebook, nearly every visible product is powered by machine learning algorithms at its core, from News Feed ranking to language translation to anomaly detection. Scaling these products to billions of global users has uncovered many fascinating scaling challenges at every layer in the systems stack, with bottlenecks surfacing in compute, storage, and network. Meanwhile, at this scale, many research ideas hit their practical limits, and the ultimate solutions often run counter to common assumptions. Being at the forefront of today’s Deep Learning Era enables a unique view into some early signals about which research directions are particularly intriguing, and which are potentially misguided and/or overinvested.</p>
     </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
      </div>
    </div>
  </div>
</div>

<div class="modal fade" id="charlesModal" tabindex="-1" role="dialog" aria-hidden="true">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
        <h4 class="modal-title">Reviewing models, prepublication models, and other things that tend to make people upset</h4>
      </div>
      <div class="modal-body">
      <p>Within the past decade, we have seen a lot of change in publication and review models in computer science. As more and more conferences move to double-blind review, more and more authors are moving to placing their papers publicly on the internet before or during review. In 2017, around 23% of top-tier papers in computer science were posted to arxiv.org alone. <br /><br />

      Many people have pointed out that these two trends seem incompatible,sometimes using language like "the death of double blind reviewing". <br /><br />

      I'll talk about how to square this circle. I will argue: <br /><br />

• Prepublication and double-blind are both good things, and are not incompatible.<br />
• We should design our review process to be robust to occasional unblinding.<br />
• Both authors and reviewers have a responsibility to help maintain author anonymity.<br />
• Anonymous prepublication is not workable.<br />
• We should base decisions about reviewing models on data rather than on speculation or individual taste.</p>
     </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
      </div>
    </div>
  </div>
</div>

<div class="modal fade" id="sebastianModal" tabindex="-1" role="dialog" aria-hidden="true">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
        <h4 class="modal-title">Are we making progress?</h4>
      </div>
      <div class="modal-body">
      <p>As a research community we should strive for research progress of the community as a whole. To understand progress I will discuss a simple model of a research frontier that we advance, and then discuss the biggest challenge that I see for certain areas of the ML community, namely a lack of signal on whether progress is made due to the lack of a common task framework.</p>
     </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
      </div>
    </div>
  </div>
</div>


<h2>Accepted Papers</h2>


<dl>
<dt><span class="label label-primary">Spotlight Talk</span> Surprising Negative Results for Generative Adversarial Tree Search [<a href="https://www.dropbox.com/s/0tw57s6wqflx309/CRACT_2018_paper_2.pdf?dl=0">paper</a>]</dt>
<dd>Kamyar Azizzadenesheli, Brandon Yang, Weitang Liu, Emma Brunskill, Zachary Lipton and Animashree Anandkumar.</dd> 
</dl>
<dl>
<dt>Deriving the Recurrent Neural Network Definition and RNN Unrolling Using Signal Processing [<a href="https://www.dropbox.com/s/qqplxzbmb0wx763/CRACT_2018_paper_3.pdf?dl=0">paper</a>]</dt>
<dd>Alex Sherstinsky.</dd> 
</dl>
<dl>
<dt>Critiquing Intuitions for Learning Rate Restarts [<a href="https://www.dropbox.com/s/szn5f8w0t6r2oqu/CRACT_2018_paper_4.pdf?dl=0">paper</a>]</dt>
<dd>Akhilesh Gotmare, Nitish Shirish Keskar, Caiming Xiong and Richard Socher.</dd> 
</dl>
<dl>
<dt>Lebesgue Regression [<a href="https://www.dropbox.com/s/6w7v4gpbvd83m24/CRACT_2018_paper_5.pdf?dl=0">paper</a>]</dt>
<dd>Yotam Hechtlinger, Niccolo Dalmasso, Alessandro Rinaldo and Larry Wasserman.</dd> 
</dl>
<dl>
<dt><span class="label label-primary">Oral</span> Opportunities for machine learning research to support fairness in industry practice [<a href="https://www.dropbox.com/s/z0yay2twgpugxjq/CRACT_2018_paper_6.pdf?dl=0">paper</a>]</dt>
<dd>Kenneth Holstein, Jennifer Wortman Vaughan, Hal Daumé Iii, Miroslav Dudík and Hanna Wallach.</dd> 
</dl>
<dl>
<dt>An Evaluation of the Human-Interpretability of Explanation [<a href="https://www.dropbox.com/s/5knzhdpvwkqon65/CRACT_2018_paper_8.pdf?dl=0">paper</a>]</dt>
<dd>Isaac Lage, Emily Chen, Jeffrey He, Menaka Narayanan, Samuel Gershman, Been Kim and Finale Doshi-Velez.</dd> 
</dl>
<dl>
<dt><span class="label label-primary">Spotlight Talk</span> Conference ticket allocation via non-uniform random selection to address systemic biases [<a href="https://www.dropbox.com/s/m5pxuqjag6ovc3g/CRACT_2018_paper_10.pdf?dl=0">paper</a>]</dt>
<dd>Jessica Thompson, Laurent Dinh, Layla El Asri and Nicolas Le Roux.</dd> 
</dl>
<dl>
<dt>Do Deep Convolutional Network Layers Need to be Trained End-to-End? [<a href="https://www.dropbox.com/s/juyvvhm72xpkng7/CRACT_2018_paper_12.pdf?dl=0">paper</a>]</dt>
<dd>Eugene Belilovsky, Michael Eickenberg and Edouard Oyallon.</dd> 
</dl>
<dl>
<dt>Characterising activation functions by their backward dynamics around forward fixed points [<a href="https://www.dropbox.com/s/wlmw38c7eq7kqoq/CRACT_2018_paper_14.pdf?dl=0">paper</a>]</dt>
<dd>Pieter-Jan Hoedt, Sepp Hochreiter and Günter Klambauer.</dd> 
</dl>
<dl>
<dt>Bad practices in evaluation methodology relevant to class-imbalanced problems [<a href="https://www.dropbox.com/s/c2tjqkb2pgqwkn6/CRACT_2018_paper_15.pdf?dl=0">paper</a>]</dt>
<dd>Jan Brabec and Lukas Machlica.</dd> 
</dl>
<dl>
<dt>On the Evaluation of Common-Sense Reasoning in Natural Language Understanding [<a href="https://www.dropbox.com/s/uoxei4kq4nh7omh/CRACT_2018_paper_17.pdf?dl=0">paper</a>]</dt>
<dd>Paul Trichelair, Ali Emami, Jackie Cheung, Adam Trischler, Kaheer Suleman and Fernando Diaz.</dd> 
</dl>
<dl>
<dt>Questioning the assumptions behind fairness solutions [<a href="https://www.dropbox.com/s/cpskjl44fxw9vlg/CRACT_2018_paper_18.pdf?dl=0">paper</a>]</dt>
<dd>Rebekah Overdorf, Bogdan Kulynych, Ero Balsa, Carmela Troncoso and Seda Guerses.</dd> 
</dl>
<dl>
<dt>Rethinking Layer-wise Feature Amounts in Convolutional Neural Network Architectures [<a href="https://www.dropbox.com/s/vjt0on2dxizzv8v/CRACT_2018_paper_19.pdf?dl=0">paper</a>]</dt>
<dd>Martin Mundt, Sagnik Majumder, Tobias Weis and Visvanathan Ramesh.</dd> 
</dl>
<dl>
<dt><span class="label label-primary">Spotlight Talk</span> Distilling Information from a Flood: A Possibility for the Use of Meta-Analysis and Systematic Review in Machine Learning Research [<a href="https://www.dropbox.com/s/xeewaajsjpo2ynq/CRACT_2018_paper_20.pdf?dl=0">paper</a>]</dt>
<dd>Peter Henderson and Emma Brunskill.</dd> 
</dl>
<dl>
<dt>Towards Optimal Design of Datasets and Validation Scheme for Autonomous Driving [<a href="https://www.dropbox.com/s/6d8rwq6lbdhubvb/CRACT_2018_paper_21.pdf?dl=0">paper</a>]</dt>
<dd>Michal Uricar, Pavel Krizek, David Hurych and Senthil Yogamani.</dd>
</dl>
<dl>
<dt>Bridging the Generalization Gap: Training Robust Models on Confounded Biological Data [<a href="https://www.dropbox.com/s/rjyxzruod5yqukw/CRACT_2018_paper_22.pdf?dl=0">paper</a>]</dt>
<dd>Tzu-Yu Liu, Ajay Kannan, Adam Drake, Marvin Bertin and Nathan Wan.</dd> 
</dl>
<dl>
<dt><span class="label label-primary">Spotlight Talk</span> Let's Play Again: Variability of Deep Reinforcement Learning Agents in Atari Environments [<a href="https://www.dropbox.com/s/gwlr1p9tudc80ag/CRACT_2018_paper_23.pdf?dl=0">paper</a>]</dt>
<dd>Kaleigh Clary, Emma Tosch, John Foley and David Jensen.</dd> 
</dl>
<dl>
<dt><span class="label label-primary">Spotlight Talk</span> Please Stop Explaining Black Box Models for High Stakes Decisions [<a href="https://www.dropbox.com/s/i6nz17irnb8lbq5/CRACT_2018_paper_24.pdf?dl=0">paper</a>]</dt>
<dd>Cynthia Rudin.</dd> 
</dl>
<dl>
<dt>Causal importance of orientation selectivity for generalization in image recognition [<a href="https://www.dropbox.com/s/fh430hbu35j0tux/CRACT_2018_paper_25.pdf?dl=0">paper</a>]</dt>
<dd>Jumpei Ukita.</dd> 
</dl>
<dl>
<dt>Life at the edge: accelerators and obstacles to emerging ML-enabled research ﬁelds [<a href="https://www.dropbox.com/s/uevxjkaxwczqhed/CRACT_2018_paper_26.pdf?dl=0">paper</a>]</dt>
<dd>Soukayna Mouatadid and Steve Easterbrook.</dd>
</dl>
<dl>
<dt>Generalization in Deep Reinforcement Learning [<a href="https://www.dropbox.com/s/m0nyan7pl8zn3qe/CRACT_2018_paper_27.pdf?dl=0">paper</a>]</dt>
<dd>Sam Witty, Jun Ki Lee, Emma Tosch, Akanksha Atrey, David Jensen and Michael Littman.</dd> 
</dl>
<dl>
<dt>On the Implicit Assumptions of GANs [<a href="https://www.dropbox.com/s/uw3vuf3vzox1259/CRACT_2018_paper_28.pdf?dl=0">paper</a>]</dt>
<dd>Ke Li and Jitendra Malik.</dd> 
</dl>
<dl>
<dt><span class="label label-primary">Oral</span> Expanding search in the space of empirical ML [<a href="https://www.dropbox.com/s/1j5hh1kojtkw5mt/CRACT_2018_paper_29.pdf?dl=0">paper</a>]</dt>
<dd>Bronwyn Woods.</dd> 
</dl>
<dl>
<dt>Refactoring Machine Learning [<a href="https://www.dropbox.com/s/fogthd6r53g1jv1/CRACT_2018_paper_32.pdf?dl=0">paper</a>]</dt>
<dd>Andrew Ross and Jessica Forde.</dd> 
</dl>
<dl>
<dt>Evaluating Generative Adversarial Networks on Explicitly Parameterized Distributions [<a href="https://www.dropbox.com/s/gkwnfwy5jk0vgho/CRACT_2018_paper_33.pdf?dl=0">paper</a>]</dt>
<dd>Shayne O'Brien, Matthew Groh and Abhimanyu Dubey.</dd> 
</dl>
<dl>
<dt>The Sheepdog and the Telescope: Application Paradigms in Machine Learning [<a href="https://www.dropbox.com/s/7eqe4r79ljo6c1b/CRACT_2018_paper_34.pdf?dl=0">paper</a>]</dt>
<dd>David Mimno.</dd> 
</dl>
<dl>
<dt><span class="label label-primary">Spotlight Talk</span> What's in a name? It's time to nip NIPS [<a href="https://www.dropbox.com/s/sv9qcfnv42zbmib/CRACT_2018_paper_35.pdf?dl=0">paper</a>]</dt>
<dd>Daniela Witten, Elana Fertig, Anima Anandkumar and Jeff Dean.</dd> 
</dl>
<dl>
<dt><span class="label label-primary">Spotlight Talk</span> Theoretical guarantees and empirical evaluation: how large is the gap? [<a href="https://www.dropbox.com/s/2pvr6puh9h6us6y/CRACT_2018_paper_36.pdf?dl=0">paper</a>]</dt>
<dd>Marina Meila and Yali Wan.</dd> 
</dl>
<dl>
<dt>Dataset Bias in the Natural Sciences: A Case Study in Chemical Reaction Prediction and Synthesis Design [<a href="https://www.dropbox.com/s/j1p5vpunz6mr3hb/CRACT_2018_paper_37.pdf?dl=0">paper</a>]</dt>
<dd>Ryan-Rhys Griffiths, Philippe Schwaller and Alpha Lee.</dd> 
</dl>
<dl>
<dt><span class="label label-primary">Oral</span> Avoiding a Tragedy of the Commons in the Peer Review Process [<a href="https://www.dropbox.com/s/izwjay394299e1r/CRACT_2018_paper_38.pdf?dl=0">paper</a>]</dt>
<dd>D. Sculley, Jasper Snoek and Alex Wiltschko.</dd> 
</dl>
<dl>
<dt><span class="label label-primary">Oral</span> Using Cumulative Distribution Based Performance Analysis to Benchmark Models [<a href="https://www.dropbox.com/s/nyt926dq4dbj3kw/CRACT_2018_paper_39.pdf?dl=0">paper</a>]</dt>
<dd>Scott Jordan, Daniel Cohen and Phillip Thomas.</dd> 
</dl>
<dl>
<dt><span class="label label-primary">Spotlight Talk</span> Can VAEs Generate Novel Examples? [<a href="https://www.dropbox.com/s/747hie5k8dumkyo/CRACT_2018_paper_40.pdf?dl=0">paper</a>]</dt>
<dd>Alican Bozkurt, Babak Esmaeili, Dana Brooks, Jennifer Dy and Jan-Willem Van de Meent.</dd> 
</dl>
<dl>
<dt>Visual Dialogue without Vision or Dialogue [<a href="https://www.dropbox.com/s/cuyvqvwb84inykb/CRACT_2018_paper_41.pdf?dl=0">paper</a>]</dt>
<dd>Daniela Massiceti, Puneet Dokania, Siddharth Narayanaswamy and Phil Torr.</dd> 
</dl>
<dl>
<dt><span class="label label-primary">Spotlight Talk</span> Code as Scholarship: Extensible Software Experiments [<a href="https://www.dropbox.com/s/cwtzh3lsp8i3qhd/CRACT_2018_paper_42.pdf?dl=0">paper</a>]</dt>
<dd>Jessica Forde.</dd> 
</dl>
<dl>
<dt><span class="label label-primary">Spotlight Talk</span> Language GANs Falling Short [<a href="https://www.dropbox.com/s/qkl6yelhew3bq1f/CRACT_2018_paper_44.pdf?dl=0">paper</a>]</dt>
<dd>Massimo Caccia, Lucas Caccia, Laurent Charlin, William Fedus, Hugo Larochelle and Joelle Pineau.</dd>
</dl>
<dl>
<dt>Generalization in anti-causal learning [<a href="https://www.dropbox.com/s/6zbp7i992oyjx4p/CRACT_2018_paper_46.pdf?dl=0">paper</a>]</dt>
<dd>Niki Kilbertus, Giambattista Parascandolo and Bernhard Schölkopf.</dd> 
</dl>







<h3>Contact </h3>
<p>Please direct any questions to <a href="ml.critique.correct@gmail.com" class="btn btn-default btn-xs" role="button">ml.critique.correct@gmail.com</a>.</p>



	<hr>

      <h2>References</h2>
      
      <dl class="dl-horizontal">
      
      	<dt>[1]</dt>
	  	<dd> Mania, H., Guy, A., & Recht, B. (2018). Simple random search provides a competitive approach to reinforcement learning. arXiv preprint arXiv:1803.07055.</dd>

      	<dt>[2]</dt>
	  	<dd>Rainforth, T., Kosiorek, A. R., Le, T. A., Maddison, C. J., Igl, M., Wood, F., & Teh, Y. W. (2018). Tighter variational bounds are not necessarily better. ICML.</dd>

		<dt>[3]</dt>
	  	<dd>Torralba, A., & Efros, A. A. (2011). Unbiased look at dataset bias. In Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on (pp. 1521-1528). IEEE.</dd>

	  	<dt>[4]</dt>
	  	<dd>Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., & Fergus, R. (2013). Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199.</dd>
	  	
	  	<dt>[5]</dt>
	  	<dd>Mescheder, L., Geiger, A., Nowozin S. (2018) Which Training Methods for GANs do actually Converge? ICML</dd>
	  	
	  	<dt>[6]</dt>
	  	<dd>Daumé III, H. (2009). Frustratingly easy domain adaptation. arXiv preprint arXiv:0907.1815</dd>	  

		<dt>[7]</dt>
	  	<dd>Urban, G., Geras, K. J., Kahou, S. E., Wang, O. A. S., Caruana, R., Mohamed, A., ... & Richardson, M. (2016). Do deep convolutional nets really need to be deep (or even convolutional)?.</dd>
	  
	  	<dt>[8]</dt>
	  	<dd>Henderson, P., Islam, R., Bachman, P., Pineau, J., Precup, D., & Meger, D. (2017). Deep reinforcement learning that matters. arXiv preprint arXiv:1709.06560.</dd>

      	<dt>[9]</dt>
	  	<dd>Narayanan, M., Chen, E., He, J., Kim, B., Gershman, S., & Doshi-Velez, F. (2018). How do Humans Understand Explanations from Machine Learning Systems? An Evaluation of the Human-Interpretability of Explanation. arXiv preprint arXiv:1802.00682.</dd>
	  	
 		<dt>[10]</dt>
	  	<dd>Schulam, S., Saria S. (2017). Reliable Decision Support using Counterfactual Models. NIPS.</dd>

	  	<dt>[11]</dt>
	  	<dd>Rahimi, A. (2017). Let's take machine learning from alchemy to electricity. Test-of-time award presentation, NIPS. </dd>

      	<dt>[12]</dt>
	  	<dd>Lucic, M., Kurach, K., Michalski, M., Gelly, S., Bousquet, O. (2018). Are GANs Created Equal? A Large-Scale Study. arXiv preprint arXiv:1711.10337.</dd>

      	<dt>[13]</dt>
	  	<dd>Le, T.A., Kosiorek, A.R., Siddharth, N., Teh, Y.W. and Wood, F., (2018). Revisiting Reweighted Wake-Sleep. arXiv preprint arXiv:1805.10469.</dd>

      	<dt>[14]</dt>
	  	<dd>Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J. and Mané, D., (2016). Concrete problems in AI safety. arXiv preprint arXiv:1606.06565.</dd>
      	
      	<dt>[15]</dt>
	  	<dd>Sutton, C. (2018) Making unblinding manageable: Towards reconciling prepublication and double-blind review. http://www.theexclusive.org/2017/09/arxiv-double-blind.html</dd>

      	<dt>[16]</dt>
	  	<dd>Langford, J. (2018) ICML Board and Reviewer profiles. http://hunch.net/?p=8962378</dd>

      	<dt>[17]</dt>
	  	<dd>Lipton, Zachary C., and Jacob Steinhardt (2018). "Troubling Trends in Machine Learning Scholarship." arXiv preprint arXiv:1807.03341.</dd>

	  	<dt>[18]</dt>
  		<dd>Kaushik, Divyansh, and Zachary C. Lipton (2018). "How Much Reading Does Reading Comprehension Require? A Critical Investigation of Popular Benchmarks." arXiv preprint arXiv:1808.04926. </dd>

	  	<!--<dt>[19]</dt>
	  	<dd>Faber F. A., Lindmaa A., von Lilienfeld, O. A., Armiento, R. (2016). <em>Machine learning energies of 2 million elpasolite (A B C 2 D 6) crystals</em>. Phys. Rev. Lett., 117(13), 135502.</dd>
	  	  	
	  	<dt>[20]</dt>
	  	<dd>Gomez-Bombarelli, R., Duvenaud, D., Hernandez-Lobato, J. M., Aguilera-Iparraguirre, J., Hirzel, T. D., Adams, R. P., Aspuru-Guzik, A. (2016). <em>Automatic chemical design using a data-driven continuous representation of molecules</em>. arXiv preprint arXiv:1610.02415.</dd>

	  	<dt>[21]</dt>
	  	<dd>Wei, J. N., Duvenaud, D, Aspuru-Guzik, A. (2016). <em>Neural networks for the prediction of organic chemistry reactions</em>. ACS Cent. Sci., 2(10), 725-732.</dd>
	  	
	  	<dt>[22]</dt>
	  	<dd>Sadowski, P., Fooshee, D., Subrahmanya, N., Baldi, P. (2016). <em>Synergies between quantum mechanics and machine learning in reaction prediction</em>. J. Chem. Inf. Model., 56(11), 2125-2128.</dd>

	  	<dt>[23]</dt>
	  	<dd>Lee, A. A., Brenner, M. P., Colwell L. J. (2016). <em>Predicting protein-ligand affinity with a random matrix framework</em>. Proc. Natl. Acad. Sci., 113(48), 13564-13569.</dd>

	  	<dt>[24]</dt>
	  	<dd>Behler, J. (2016). <em>Perspective: Machine learning potentials for atomistic simulations</em>. J. Chem. Phys., 145(17), 170901.</dd>

	  	<dt>[25]</dt>
	  	<dd>De, S., Bartók, A. P., Csányi, G., Ceriotti, M. (2016). <em>Comparing molecules and solids across structural and alchemical space</em>. Phys. Chem. Chem. Phys., 18(20), 13754-13769.</dd>

      	<dt>[26]</dt>
	  	<dd>Schütt, K. T., Arbabzadah, F., Chmiela, S., Müller, K.-R., Tkatchenko, A. (2017). <em>Quantum-chemical insights from deep tensor neural networks</em>. Nat. Commun., 8, 13890.</dd>

	  	<dt>[27]</dt>
	  	<dd>Segler, M. H., Waller, M. P. (2017). <em>Neural‐symbolic machine learning for retrosynthesis and reaction prediction</em>. ‎Chem. Eur. J., 23(25), 5966-5971.</dd>

	  	<dt>[28]</dt>
	  	<dd>Kusner, M. J., Paige, B., Hernández-Lobato, J. M. (2017). <em>Grammar variational autoencoder</em>. arXiv preprint arXiv:1703.01925.</dd>

	  	<dt>[29]</dt>
  		<dd>Coley, C. W., Barzilay, R., Jaakkola, T. S., Green, W. H., Jensen K. F. (2017). <em>Prediction of organic reaction outcomes using machine learning</em>. ACS Cent. Sci., 3(5), 434-443.</dd>

	  	<dt>[30]</dt>
	  	<dd>Altae-Tran, H., Ramsundar, B., Pappu, A. S., Pande, V. (2017). <em>Low data drug discovery with one-shot learning</em>. ACS Cent. Sci., 3(4), 283-293.</dd>

	  	<dt>[31]</dt>
	  	<dd>Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O., Dahl, G. E. (2017). <em>Neural message passing for quantum chemistry</em>. arXiv preprint arXiv:1704.01212.</dd>

	  	<dt>[32]</dt>
	  	<dd>Chmiela, S., Tkatchenko, A., Sauceda, H. E., Poltavsky, Igor, Schütt, K. T., Müller, K.-R. (2017). <em>Machine learning of accurate energy-conserving molecular force fields</em>. Sci. Adv., 3(5), e1603015.</dd>

	  	<dt>[33]</dt>
	  	<dd>Ju, S., Shiga T., Feng L., Hou Z., Tsuda, K., Shiomi J. (2017). <em>Designing nanostructures for phonon transport via bayesian optimization</em>. Phys. Rev. X, 7(2), 021024.</dd>

	  	<dt>[34]</dt>
	  	<dd>Ramakrishnan, R, von Lilienfeld, A. (2017). <em>Machine learning, quantum chemistry, and chemical space</em>. Reviews in Computational Chemistry, 225-256.</dd>

	  	<dt>[35]</dt>
	  	<dd>Hernandez-Lobato, J. M., Requeima, J., Pyzer-Knapp, E. O., Aspuru-Guzik, A. (2017). <em>Parallel and distributed Thompson sampling for large-scale accelerated exploration of chemical space</em>. arXiv preprint arXiv:1706.01825.</dd>

	  	<dt>[36]</dt>
	  	<dd>Smith, J., Isayev, O., Roitberg, A. E. (2017). <em>ANI-1: an extensible neural network potential with DFT accuracy at force field computational cost</em>. Chem. Sci., 8(4), 3192-3203.</dd>

	  	<dt>[37]</dt>
	  	<dd>Brockherde, F., Li, L., Burke, K., Müller, K.-R. <em>By-passing the Kohn-Sham equations with machine learning</em>. Nat. Commun., 8, 872.</dd>

		<dt>[38]</dt>
		<dd>Schütt, K. T., Kindermans, P. J., Sauceda, H. E., Chmiela, S., Tkatchenko, A., Müller, K. R. (2017). <em>MolecuLeNet: A continuous-filter convolutional neural network for modeling quantum interactions</em>. NIPS 2017.</dd>

		<dt>[39]</dt>
	  	<dd>Chmiela, S., Sauceda, H. E., Müller, K.-R., Tkatchenko, A. <em>Towards Exact Molecular Dynamics Simulations with Machine-Learned Force Fields</em>. Nat. Commun., accepted</dd>

-->
	  </dl>
    </div> <!-- /container -->


    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="assets/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>
